@article{kumar_melgan_2019,
  title={Melgan: Generative adversarial networks for conditional waveform synthesis},
  author={Kumar, Kundan and Kumar, Rithesh and De Boissiere, Thibault and Gestin, Lucas and Teoh, Wei Zhen and Sotelo, Jose and De Brebisson, Alexandre and Bengio, Yoshua and Courville, Aaron C},
  journal={NeurIPS},
  year={2019}
}

@article{liu_semanticodec_2024,
  title={Semanticodec: An ultra low bitrate semantic audio codec for general sound},
  author={Liu, Haohe and Xu, Xuenan and Yuan, Yi and Wu, Mengyue and Wang, Wenwu and Plumbley, Mark D},
  journal={JSTSP},
  year={2024},
}

@inproceedings{pine_eval_2025,
  title     = {{Practical & Contextual Speech Synthesis Evaluation}},
  author    = {Aidan Pine and Delaney Lothian and Sonya Bird and Marion Caldecott and  MENEŦIYE and  PENÁĆ and Korin Richmond and Tye Swallow and  SX̱EDŦELISIYE and Cassia Valentini-Botinhao and Dan Wells and Patrick Littell},
  year      = {2025},
  booktitle = {SSW},
}


@article{taylor_festival_1998,
  title={The architecture of the Festival speech synthesis system},
  author={Taylor, Paul and Black, Alan W and Caley, Richard},
  year={1998},
  publisher={ISCA}
}


@article{tokuda_hts_2013,
  title={Speech synthesis based on hidden Markov models},
  author={Tokuda, Keiichi and Nankaku, Yoshihiko and Toda, Tomoki and Zen, Heiga and Yamagishi, Junichi and Oura, Keiichiro},
  journal={Proceedings of the IEEE},
  year={2013},
}


@inproceedings{kong_diffwave_2021,
  title={DiffWave: A Versatile Diffusion Model for Audio Synthesis},
  author={Kong, Zhifeng and Ping, Wei and Huang, Jiaji and Zhao, Kexin and Catanzaro, Bryan},
  booktitle={International Conference on Learning Representations},
  journal={ICLR},
  year={2021}
}



@article{lakhotia_gslm_2021,
  title={On generative spoken language modeling from raw audio},
  author={Lakhotia, Kushal and Kharitonov, Eugene and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Abdelrahman and others},
  journal={TACL},
  year={2021},
}

@inproceedings{prenger_waveglow_2019,
  title={Waveglow: A flow-based generative network for speech synthesis},
  author={Prenger, Ryan and Valle, Rafael and Catanzaro, Bryan},
  booktitle={ICASSP},
  year={2019},
}

@inproceedings{kim_vits_2021,
  title={Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech},
  author={Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  booktitle={ICML},
  year={2021},
  organization={PMLR}
}



@inproceedings{park_speechssm_2025,
  title={Long-form speech generation with spoken language models},
  author={Park, Se Jin and Salazar, Julian and Jansen, Aren and Kinoshita, Keisuke and Ro, Yong Man and Skerry-Ryan, RJ},
  booktitle={ICML},
  year={2025}
}

@inproceedings{ling_blizzard_2021,
  title={The blizzard challenge 2021},
  author={Ling, Zhen-Hua and Zhou, Xiao and King, Simon},
  booktite={The Blizzard Challenge},
  year={2021}
}

@misc{ttsarena,
    title        = {Text to Speech Arena},
    author       = {mrfakename and Srivastav, Vaibhav and Fourrier, Clémentine and Pouget, Lucain and Lacombe, Yoach and main and Gandhi, Sanchit},
    year         = 2024,
    howpublished = "\url{https://huggingface.co/spaces/TTS-AGI/TTS-Arena}"
}

@misc{vctk,
  title={English multi-speaker corpus for CSTR voice cloning toolkit},
  author={Yamagishi, Junichi},
  year={2013},
howpublished="\url{http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html}"
}

@inproceedings{oord_wavenet_2016,
  title={{WaveNet}: A Generative Model for Raw Audio},
  author={van den Oord, A{\"a}ron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  booktitle={SSW},
  year={2016}
}


@article{tan_survey_2021,
  title={A survey on neural speech synthesis},
  author={Tan, Xu and Qin, Tao and Soong, Frank and Liu, Tie-Yan},
  journal={arXiv:2106.15561},
  year={2021}
}

@inproceedings{wu_merlin_2016,
  title={Merlin: An open source neural network speech synthesis system},
  author={Wu, Zhizheng and Watts, Oliver and King, Simon},
  booktitle={SSW},
  year={2016}
}

@inproceedings{yao_g2p_2015,
  title={Sequence-to-sequence neural net models for grapheme-to-phoneme conversion},
  author={Yao, Kaisheng and Zweig, Geoffrey},
  booktitle={Proc. Interspeech 2015},
  pages={3330--3334},
  year={2015}
}


@article{chen_f5_2024,
      title={F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching}, 
      author={Yushen Chen and Zhikang Niu and Ziyang Ma and Keqi Deng and Chunhui Wang and Jian Zhao and Kai Yu and Xie Chen},
      journal={arXiv:2410.06885},
      year={2024},
  }

@inproceedings{wang_slmeval_2024,
  title={Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model},
  author={Wang, Siyang and Sz{\'e}kely, {\'E}va},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  year={2024}
}

@article{kong_hifigan_2020,
  title={Hifi-GAN: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={NeurIPS},
  year={2020}
}


@article{kim_glowtts_2020,
  title={{Glow-TTS}: A generative flow for text-to-speech via monotonic alignment search},
  author={Kim, Jaehyeon and Kim, Sungwon and Kong, Jungil and Yoon, Sungroh},
  journal={NeurIPS},
  year={2020}
}

@InProceedings{kalchbrenner_wavernn_2018,
  title = 	 {Efficient Neural Audio Synthesis},
  author =       {Kalchbrenner, Nal and Elsen, Erich and Simonyan, Karen and Noury, Seb and Casagrande, Norman and Lockhart, Edward and Stimberg, Florian and van den Oord, Aaron and Dieleman, Sander and Kavukcuoglu, Koray},
  booktitle = 	 {ICML},
  year = 	 {2018},
}

@inproceedings{peng_paranet_2020,
  title={Non-autoregressive neural text-to-speech},
  author={Peng, Kainan and Ping, Wei and Song, Zhao and Zhao, Kexin},
  booktitle={ICML},
  year={2020},
}

@inproceedings{arik_deepvoice_2017,
  title={Deep Voice: Real-time neural text-to-speech},
  author={Ar{\i}k, Sercan {\"O} and Chrzanowski, Mike and Coates, Adam and Diamos, Gregory and Gibiansky, Andrew and Kang, Yongguo and Li, Xian and Miller, John and Ng, Andrew and Raiman, Jonathan and others},
  booktitle={ICML},
  year={2017},
}

@article{gibiansky_deepvoice2_2017,
  title={Deep voice 2: Multi-speaker neural text-to-speech},
  author={Gibiansky, Andrew and Arik, Sercan and Diamos, Gregory and Miller, John and Peng, Kainan and Ping, Wei and Raiman, Jonathan and Zhou, Yanqi},
  journal={NeurIPS},
  year={2017}
}

@inproceedings{ling_hybrid_2007,
  title={{HMM}-based hierarchical unit selection combining Kullback-Leibler divergence with likelihood criterion},
  author={Ling, Zhen-Hua and Wang, Ren-Hua},
  booktitle={ICASSP},
  year={2007},
}

@article{tukoda_hmm_2013,
  author={Tokuda, Keiichi and Nankaku, Yoshihiko and Toda, Tomoki and Zen, Heiga and Yamagishi, Junichi and Oura, Keiichiro},
  journal={Proceedings of the IEEE}, 
  title={Speech Synthesis Based on Hidden Markov Models}, 
  year={2013},
}

@inproceedings{hunt_unit_1996,
  title={Unit selection in a concatenative speech synthesis system using a large speech database},
  author={Hunt, A.J. and Black, A.W.},
  booktitle={ICASSP},
  year={1996},
}

@inproceedings{le_voicebox_2023,
 author = {Le, Matthew and Vyas, Apoorv and Shi, Bowen and Karrer, Brian and Sari, Leda and Moritz, Rashel and Williamson, Mary and Manohar, Vimal and Adi, Yossi and Mahadeokar, Jay and Hsu, Wei-Ning},
 booktitle = {NeurIPS},
 title = {Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale},
 year = {2023}
}

@article{wang_valle_2023,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@article{badlani_multilingual_2023,
	title = {Multilingual {Multiaccented} {Multispeaker} {TTS} with {RADTTS}},
	journal = {arXiv:2301.10335},
	author = {Badlani, Rohan and Valle, Rafael and Shih, Kevin J and Santos, João Felipe and Gururani, Siddharth and Catanzaro, Bryan},
	year = {2023},
}

@article{borsos_soundstorm_2023,
  title={Soundstorm: Efficient parallel audio generation},
  author={Borsos, Zal{\'a}n and Sharifi, Matt and Vincent, Damien and Kharitonov, Eugene and Zeghidour, Neil and Tagliasacchi, Marco},
  journal={arXiv:2305.09636},
  year={2023}
}

@inproceedings{du_multi-speaker_2023,
	title = {Multi-{Speaker} {Multi}-{Lingual} {VQTTS} {System} for {LIMMITS} 2023 {Challenge}},
	booktitle = {{ICASSP}},
	author = {Du, Chenpeng and Guo, Yiwei and Shen, Feiyu and Yu, Kai},
	year = {2023},
}

@article{zhang_speak_2023,
	title = {Speak {Foreign} {Languages} with {Your} {Own} {Voice}: {Cross}-{Lingual} {Neural} {Codec} {Language} {Modeling}},
	journal = {arXiv:2303.03926},
	author = {Zhang, Ziqiang and Zhou, Long and Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and {others}},
	year = {2023},
}

@inproceedings{ren_revisiting_2022,
	title = {Revisiting {Over}-{Smoothness} in {Text} to {Speech}},
	booktitle = {{ACL}},
	author = {Ren, Yi and Tan, Xu and Qin, Tao and Zhao, Zhou and Liu, Tie-Yan},
	year = {2022},
}

@article{ren_fastspeech_2021,
	title = {{FastSpeech} 2: {Fast} and {High}-{Quality} {End}-to-{End} {Text} to {Speech}},
	journal = {ICLR},
	author = {Ren, Yi and Hu, Chenxu and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
	year = {2021},
}

@inproceedings{huang_fastdiff_2022,
	title = {{FastDiff}: {A} {Fast} {Conditional} {Diffusion} {Model} for {High}-{Quality} {Speech} {Synthesis}},
	booktitle = {{IJCAI}},
	author = {Huang, R and Lam, MWY and Wang, J and Su, D and Yu, D and Ren, Y and Zhao, Z},
	year = {2022},
}

@inproceedings{kroger_articulatory_2023,
	title = {Articulatory {Speech} {Synthesis} in the {Context} of {Speech} {Research} and {Speech} {Technology}: {Review} and {Prospect}},
	booktitle = {{ESSV}},
	author = {Kröger, Bernd J.},
	year = {2023},
}

@inproceedings{shen_natural_2018,
	title = {Natural {TTS} synthesis by conditioning wavenet on mel spectrogram predictions},
	booktitle = {{ICASSP}},
	author = {Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and {others}},
	year = {2018},
}

@article{casanova_xtts_2024,
	title = {{XTTS}: a {Massively} {Multilingual} {Zero}-{Shot} {Text}-to-{Speech} {Model}},
	journal = {arXiv:2401.02839},
	author = {Casanova, Edresson and Davis, Kelly and Gölge, Eren and Göknar, Görkem and Gulea, Iulian and Hart, Logan and Aljafari, Aya and Meyer, Joshua and Morais, Reuben and Olayemi, Samuel and {others}},
	year = {2024},
}

@article{liu_maximizing_2019,
	title = {Maximizing mutual information for tacotron},
	journal = {arXiv:1909.01145},
	author = {Liu, Peng and Wu, Xixin and Kang, Shiyin and Li, Guangzhi and Su, Dan and Yu, Dong},
	year = {2019},
}

@article{tan_naturalspeech_2024,
	title = {{NaturalSpeech}: {End}-to-end text-to-speech synthesis with human-level quality},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	author = {Tan, Xu and Chen, Jiawei and Liu, Haohe and Cong, Jian and Zhang, Chen and Liu, Yanqing and Wang, Xi and Leng, Yichong and Yi, Yuanhao and He, Lei and {others}},
	year = {2024},
}

@inproceedings{popov_gradtts_2021,
  title={Grad-tts: A diffusion probabilistic model for text-to-speech},
  author={Popov, Vadim and Vovk, Ivan and Gogoryan, Vladimir and Sadekova, Tasnima and Kudinov, Mikhail},
  booktitle={ICML},
  year={2021},
}


@article{budzianowski_pheme_2024,
	title = {Pheme: {Efficient} and {Conversational} {Speech} {Generation}},
	journal = {arXiv:2401.02839},
	author = {Budzianowski, Paweł and Sereda, Taras and Cichy, Tomasz and Vulić, Ivan},
	year = {2024},
}

@article{li_styletts_2023,
	title = {{StyleTTS} 2: {Towards} human-level text-to-speech through style diffusion and adversarial training with large speech language models},
	journal = {NeurIPS},
	author = {Li, Yinghao Aaron and Han, Cong and Raghavan, Vinay and Mischler, Gavin and Mesgarani, Nima},
	year = {2023},
}

@inproceedings{lancucki_fastpitch_2021,
	title = {Fastpitch: {Parallel} text-to-speech with pitch prediction},
	booktitle = {{ICASSP}},
	author = {Łańcucki, Adrian},
	year = {2021},
}

@article{wang_tacotron_2017,
	title = {Tacotron: {Towards} {End}-to-{End} {Speech} {Synthesis}},
	journal = {INTERSPEECH},
	author = {Wang, Yuxuan and Skerry-Ryan, RJ and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and {others}},
	year = {2017},
}

@article{andreev_hifi_2022,
	title = {{HiFi}++: a unified framework for neural vocoding, bandwidth extension and speech enhancement},
	journal = {arXiv:2203.13086},
	author = {Andreev, Pavel and Alanov, Aibek and Ivanov, Oleg and Vetrov, Dmitry},
	year = {2022},
}

@article{ju_naturalspeech_2024,
	title = {{NaturalSpeech} 3: {Zero}-shot speech synthesis with factorized codec and diffusion models},
	journal = {arXiv:2403.03100},
	author = {Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and {others}},
	year = {2024},
}

@inproceedings{casanova_yourtts_2022,
	title = {{YourTTS}: {Towards} zero-shot multi-speaker tts and zero-shot voice conversion for everyone},
	booktitle = {{ICML}},
	author = {Casanova, Edresson and Weber, Julian and Shulby, Christopher D and Junior, Arnaldo Candido and Gölge, Eren and Ponti, Moacir A},
	year = {2022},
}

@inproceedings{binkowski_high_2019,
	title = {High {Fidelity} {Speech} {Synthesis} with {Adversarial} {Networks}},
	booktitle = {{ICLR}},
	author = {Bińkowski, Mikołaj and Donahue, Jeff and Dieleman, Sander and Clark, Aidan and Elsen, Erich and Casagrande, Norman and Cobo, Luis C and Simonyan, Karen},
	year = {2019},
}

@inproceedings{kim_conditional_2021,
	title = {Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech},
	booktitle = {{ICML}},
	author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
	year = {2021},
}

@inproceedings{luo_lightspeech_2021,
	title = {Lightspeech: {Lightweight} and fast text to speech with neural architecture search},
	booktitle = {{ICASSP}},
	author = {Luo, Renqian and Tan, Xu and Wang, Rui and Qin, Tao and Li, Jinzhu and Zhao, Sheng and Chen, Enhong and Liu, Tie-Yan},
	year = {2021},
}

@article{chen_vall-e_2024,
	title = {{VALL}-{E} 2: {Neural} {Codec} {Language} {Models} are {Human} {Parity} {Zero}-{Shot} {Text} to {Speech} {Synthesizers}},
	journal = {arXiv:2406.05370},
	author = {Chen, Sanyuan and Liu, Shujie and Zhou, Long and Liu, Yanqing and Tan, Xu and Li, Jinyu and Zhao, Sheng and Qian, Yao and Wei, Furu},
	year = {2024},
}

@inproceedings{pine_requirements_2022,
	title = {Requirements and {Motivations} of {Low}-{Resource} {Speech} {Synthesis} for {Language} {Revitalization}},
	booktitle = {{ACL}},
	author = {Pine, Aidan and Wells, Dan and Brinklow, Nathan and Littell, Patrick and Richmond, Korin},
	year = {2022},
}

@inproceedings{hayashi_espnet-tts_2020,
	title = {{ESPnet}-{TTS}: {Unified}, reproducible, and integratable open source end-to-end text-to-speech toolkit},
	booktitle = {{ICASSP}},
	author = {Hayashi, Tomoki and Yamamoto, Ryuichi and Inoue, Katsuki and Yoshimura, Takenori and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya and Zhang, Yu and Tan, Xu},
	year = {2020},
}

@article{ren_fastspeech_2019,
	title = {{FastSpeech}: {Fast}, robust and controllable text to speech},
	journal = {NeurIPS},
	author = {Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
	year = {2019},
}

@article{lyth_parler_2024,
  title={Natural language guidance of high-fidelity text-to-speech with synthetic annotations},
  author={Lyth, Dan and King, Simon},
  journal={arXiv:2402.01912},
  year={2024}
}

@inproceedings{eskimez_e2_2024,
  title={{E2 TTS}: Embarrassingly easy fully non-autoregressive zero-shot {TTS}},
  author={Eskimez, Sefik Emre and Wang, Xiaofei and Thakker, Manthan and Li, Canrun and Tsai, Chung-Hsien and Xiao, Zhen and Yang, Hemin and Zhu, Zirun and Tang, Min and Tan, Xu and others},
  booktitle={SLT},
  year={2024},
}

@inproceedings{mehta_neuralhmm_2022,
  title={Neural HMMs are all you need (for high-quality attention-free TTS)},
  author={Mehta, Shivam and Sz{\'e}kely, {\'E}va and Beskow, Jonas and Henter, Gustav Eje},
  booktitle={ICASSP},
  year={2022},
}

% tts systems evaluated in ttsds

@misc{bark_2023,
    author = {Suno},
    title = {Bark},
    year = {2023},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/suno-ai/bark}},
  }
@misc{BarkVC_2023,
author = {Mylo},
title = {Bark Voice Cloning HuBERT Quantizer},
year = {2023},
publisher = {GitHub},
journal = {GitHub repository},
howpublished = {\url{https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer}},
commit = {4f42e44480fb076a52ddeb1f5ec6132d3c1ad25a}
}

@article{liao_fishspeech_2024,
      title={Fish-Speech: Leveraging Large Language Models for Advanced Multilingual Text-to-Speech Synthesis},
      author={Shijia Liao and Yuxuan Wang and Tianyu Li and Yifan Cheng and Ruoyi Zhang and Rongzhi Zhou and Yijin Xing},
      year={2024},
    journal={arXiv:2411.01156},
  }

@misc{RVCBoss_gptsovits_2024,
    author = {RVC-Boss},
    title = {GPT-SoVITS},
    year = {2024},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/RVC-Boss/GPT-SoVITS}},
  }

@article{lee_hierspeechpp_2023,
    title={Hierspeech++: Bridging the gap between semantic and acoustic representation of speech by hierarchical variational inference for zero-shot speech synthesis},
    author={Lee, Sang-Hoon and Choi, Ha-Yeong and Kim, Seung-Bin and Lee, Seong-Whan},
    journal={arXiv:2311.12454},
    year={2023}
  }

@article{wang_maskgct_2024,
    title={MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer},
    author={Wang, Yuancheng and Zhan, Haoyue and Liu, Liwei and Zeng, Ruihong and Guo, Haotian and Zheng, Jiachen and Zhang, Qiang and Zhang, Xueyao and Zhang, Shunsi and Wu, Zhizheng},
    journal={arXiv:2409.00750},
    year={2024}
  }

@inproceedings{zhang_amphion_2024,
      author={Zhang, Xueyao and Xue, Liumeng and Gu, Yicheng and Wang, Yuancheng and Li, Jiaqi and He, Haorui and Wang, Chaoren and Song, Ting and Chen, Xi and Fang, Zihao and Chen, Haopeng and Zhang, Junan and Tang, Tze Ying and Zou, Lexiao and Wang, Mingxuan and Han, Jun and Chen, Kai and Li, Haizhou and Wu, Zhizheng},
      title={Amphion: An Open-Source Audio, Music and Speech Generation Toolkit},
      booktitle={SLT},
      year={2024}
  }

@misc{sharma_metavoice_2024,
    author = {Sharma, Siddharth and Perić, Luca and Aggarwal, Vatsal and others},
    title = {MetaVoice},
    year = {2024},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/metavoiceio/metavoice-src}},
  }

@misc{lacombe_parlertts_2024,
    author = {Yoach Lacombe and Vaibhav Srivastav and Sanchit Gandhi},
    title = {ParlerTTS},
    year = {2024},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/huggingface/parler-tts}}
  }

@article{qin_openvoice_2023,
    title={Openvoice: Versatile instant voice cloning},
    author={Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
    journal={arXiv:2312.01479},
    year={2023}
  }

@inproceedings{ao_speecht5_2022,
  title={{SpeechT5}: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing},
  author={Ao, Junyi and Wang, Rui and Zhou, Long and Wang, Chengyi and Ren, Shuo and Wu, Yu and Liu, Shujie and Ko, Tom and Li, Qing and Zhang, Yu and others},
  booktitle={ACL},
  year={2022}
}

@article{betker_tortoise_2023,
    title={Better speech synthesis through scaling}, 
    author={James Betker},
    year={2023},
    journal={arXiv:2305.07243},
  }

@inproceedings{zhang_vevo_2025,
    author       = {Xueyao Zhang and Xiaohui Zhang and Kainan Peng and Zhenyu Tang and Vimal Manohar and Yingru Liu and Jeff Hwang and Dangna Li and Yuhao Wang and Julian Chan and Yuan Huang and Zhizheng Wu and Mingbo Ma},
    title        = {Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement},
    booktitle    = {{ICLR}},
    year         = {2025}
  }

@inproceedings{peng_voicecraft_2024,
  title={{VoiceCraft}: Zero-Shot Speech Editing and Text-to-Speech in the Wild},
  author={Peng, Puyuan and Huang, Po-Yao and Li, Shang-Wen and Mohamed, Abdelrahman and Harwath, David},
  booktitle={ACL},
  year={2024}
}

@misc{clapa_WhisperSpeech_2024,
    author = {Cłapa, Jakub Piotr and others},
    title = {WhisperSpeech},
    year = {2024},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/WhisperSpeech/WhisperSpeech}},
  }