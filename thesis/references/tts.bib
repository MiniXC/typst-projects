@article{badlani_multilingual_2023,
	title = {Multilingual {Multiaccented} {Multispeaker} {TTS} with {RADTTS}},
	journal = {arXiv:2301.10335},
	author = {Badlani, Rohan and Valle, Rafael and Shih, Kevin J and Santos, João Felipe and Gururani, Siddharth and Catanzaro, Bryan},
	year = {2023},
}

@inproceedings{du_multi-speaker_2023,
	title = {Multi-{Speaker} {Multi}-{Lingual} {VQTTS} {System} for {LIMMITS} 2023 {Challenge}},
	booktitle = {{ICASSP}},
	author = {Du, Chenpeng and Guo, Yiwei and Shen, Feiyu and Yu, Kai},
	year = {2023},
}

@article{zhang_speak_2023,
	title = {Speak {Foreign} {Languages} with {Your} {Own} {Voice}: {Cross}-{Lingual} {Neural} {Codec} {Language} {Modeling}},
	journal = {arXiv:2303.03926},
	author = {Zhang, Ziqiang and Zhou, Long and Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and {others}},
	year = {2023},
}

@inproceedings{ren_revisiting_2022,
	title = {Revisiting {Over}-{Smoothness} in {Text} to {Speech}},
	booktitle = {{ACL}},
	author = {Ren, Yi and Tan, Xu and Qin, Tao and Zhao, Zhou and Liu, Tie-Yan},
	year = {2022},
}

@article{ren_fastspeech_2021,
	title = {{FastSpeech} 2: {Fast} and {High}-{Quality} {End}-to-{End} {Text} to {Speech}},
	journal = {ICLR},
	author = {Ren, Yi and Hu, Chenxu and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
	year = {2021},
}

@inproceedings{huang_fastdiff_2022,
	title = {{FastDiff}: {A} {Fast} {Conditional} {Diffusion} {Model} for {High}-{Quality} {Speech} {Synthesis}},
	booktitle = {{IJCAI}},
	author = {Huang, R and Lam, MWY and Wang, J and Su, D and Yu, D and Ren, Y and Zhao, Z},
	year = {2022},
}

@inproceedings{kroger_articulatory_2023,
	title = {Articulatory {Speech} {Synthesis} in the {Context} of {Speech} {Research} and {Speech} {Technology}: {Review} and {Prospect}},
	booktitle = {{ESSV}},
	author = {Kröger, Bernd J.},
	year = {2023},
}

@inproceedings{shen_natural_2018,
	title = {Natural {TTS} synthesis by conditioning wavenet on mel spectrogram predictions},
	booktitle = {{ICASSP}},
	author = {Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and {others}},
	year = {2018},
}

@article{casanova_xtts_2024,
	title = {{XTTS}: a {Massively} {Multilingual} {Zero}-{Shot} {Text}-to-{Speech} {Model}},
	journal = {arXiv:2401.02839},
	author = {Casanova, Edresson and Davis, Kelly and Gölge, Eren and Göknar, Görkem and Gulea, Iulian and Hart, Logan and Aljafari, Aya and Meyer, Joshua and Morais, Reuben and Olayemi, Samuel and {others}},
	year = {2024},
}

@article{liu_maximizing_2019,
	title = {Maximizing mutual information for tacotron},
	journal = {arXiv:1909.01145},
	author = {Liu, Peng and Wu, Xixin and Kang, Shiyin and Li, Guangzhi and Su, Dan and Yu, Dong},
	year = {2019},
}

@article{tan_naturalspeech_2024,
	title = {{NaturalSpeech}: {End}-to-end text-to-speech synthesis with human-level quality},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	author = {Tan, Xu and Chen, Jiawei and Liu, Haohe and Cong, Jian and Zhang, Chen and Liu, Yanqing and Wang, Xi and Leng, Yichong and Yi, Yuanhao and He, Lei and {others}},
	year = {2024},
}

@article{budzianowski_pheme_2024,
	title = {Pheme: {Efficient} and {Conversational} {Speech} {Generation}},
	journal = {arXiv:2401.02839},
	author = {Budzianowski, Paweł and Sereda, Taras and Cichy, Tomasz and Vulić, Ivan},
	year = {2024},
}

@article{li_styletts_2024,
	title = {{StyleTTS} 2: {Towards} human-level text-to-speech through style diffusion and adversarial training with large speech language models},
	journal = {NeurIPS},
	author = {Li, Yinghao Aaron and Han, Cong and Raghavan, Vinay and Mischler, Gavin and Mesgarani, Nima},
	year = {2024},
}

@article{qin_openvoice_2023,
	title = {{OpenVoice}: {Versatile} {Instant} {Voice} {Cloning}},
	journal = {arXiv:2312.01479},
	author = {Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
	year = {2023},
}

@inproceedings{lancucki_fastpitch_2021,
	title = {Fastpitch: {Parallel} text-to-speech with pitch prediction},
	booktitle = {{ICASSP}},
	author = {Łańcucki, Adrian},
	year = {2021},
}

@article{wang_tacotron_2017,
	title = {Tacotron: {Towards} {End}-to-{End} {Speech} {Synthesis}},
	journal = {INTERSPEECH},
	author = {Wang, Yuxuan and Skerry-Ryan, RJ and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and {others}},
	year = {2017},
}

@article{andreev_hifi_2022,
	title = {{HiFi}++: a unified framework for neural vocoding, bandwidth extension and speech enhancement},
	journal = {arXiv:2203.13086},
	author = {Andreev, Pavel and Alanov, Aibek and Ivanov, Oleg and Vetrov, Dmitry},
	year = {2022},
}

@article{ju_naturalspeech_2024,
	title = {{NaturalSpeech} 3: {Zero}-shot speech synthesis with factorized codec and diffusion models},
	journal = {arXiv:2403.03100},
	author = {Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and {others}},
	year = {2024},
}

@inproceedings{casanova_yourtts_2022,
	title = {{YourTTS}: {Towards} zero-shot multi-speaker tts and zero-shot voice conversion for everyone},
	booktitle = {{ICML}},
	author = {Casanova, Edresson and Weber, Julian and Shulby, Christopher D and Junior, Arnaldo Candido and Gölge, Eren and Ponti, Moacir A},
	year = {2022},
}

@inproceedings{binkowski_high_2019,
	title = {High {Fidelity} {Speech} {Synthesis} with {Adversarial} {Networks}},
	booktitle = {{ICLR}},
	author = {Bińkowski, Mikołaj and Donahue, Jeff and Dieleman, Sander and Clark, Aidan and Elsen, Erich and Casagrande, Norman and Cobo, Luis C and Simonyan, Karen},
	year = {2019},
}

@inproceedings{kim_conditional_2021,
	title = {Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech},
	booktitle = {{ICML}},
	author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
	year = {2021},
}

@inproceedings{luo_lightspeech_2021,
	title = {Lightspeech: {Lightweight} and fast text to speech with neural architecture search},
	booktitle = {{ICASSP}},
	author = {Luo, Renqian and Tan, Xu and Wang, Rui and Qin, Tao and Li, Jinzhu and Zhao, Sheng and Chen, Enhong and Liu, Tie-Yan},
	year = {2021},
}

@article{chen_vall-e_2024,
	title = {{VALL}-{E} 2: {Neural} {Codec} {Language} {Models} are {Human} {Parity} {Zero}-{Shot} {Text} to {Speech} {Synthesizers}},
	journal = {arXiv:2406.05370},
	author = {Chen, Sanyuan and Liu, Shujie and Zhou, Long and Liu, Yanqing and Tan, Xu and Li, Jinyu and Zhao, Sheng and Qian, Yao and Wei, Furu},
	year = {2024},
}

@inproceedings{pine_requirements_2022,
	title = {Requirements and {Motivations} of {Low}-{Resource} {Speech} {Synthesis} for {Language} {Revitalization}},
	booktitle = {{ACL}},
	author = {Pine, Aidan and Wells, Dan and Brinklow, Nathan and Littell, Patrick and Richmond, Korin},
	year = {2022},
}

@inproceedings{hayashi_espnet-tts_2020,
	title = {{ESPnet}-{TTS}: {Unified}, reproducible, and integratable open source end-to-end text-to-speech toolkit},
	booktitle = {{ICASSP}},
	author = {Hayashi, Tomoki and Yamamoto, Ryuichi and Inoue, Katsuki and Yoshimura, Takenori and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya and Zhang, Yu and Tan, Xu},
	year = {2020},
}

@article{ren_fastspeech_2019,
	title = {{FastSpeech}: {Fast}, robust and controllable text to speech},
	journal = {NeurIPS},
	author = {Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
	year = {2019},
}

@article{lyth_parler_2024,
  title={Natural language guidance of high-fidelity text-to-speech with synthetic annotations},
  author={Lyth, Dan and King, Simon},
  journal={arXiv:2402.01912},
  year={2024}
}

@inproceedings{eskimez_e2_2024,
  title={{E2 TTS}: Embarrassingly easy fully non-autoregressive zero-shot {TTS}},
  author={Eskimez, Sefik Emre and Wang, Xiaofei and Thakker, Manthan and Li, Canrun and Tsai, Chung-Hsien and Xiao, Zhen and Yang, Hemin and Zhu, Zirun and Tang, Min and Tan, Xu and others},
  booktitle={SLT},
  year={2024},
}