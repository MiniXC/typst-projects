@inproceedings{kumar_melgan_2019,
  author    = {Kumar, Kundan and Kumar, Rithesh and De Boissiere, Thibault and Gestin, Lucas and Teoh, Wei Zhen and Sotelo, Jose and De Brebisson, Alexandre and Bengio, Yoshua and Courville, Aaron C.},
  title     = {{MelGAN}: Generative Adversarial Networks for Conditional Waveform Synthesis},
  booktitle = {Proc. NeurIPS},
  volume    = {32},
  year      = {2019},
  doi       = {10.48550/arXiv.1910.06711}
}

@article{liu_semanticodec_2024,
  author    = {Liu, Haohe and Xu, Xuenan and Yuan, Yi and Wu, Mengyue and Wang, Wenwu and Plumbley, Mark D.},
  title     = {{Semanticodec}: An Ultra Low Bitrate Semantic Audio Codec for General Sound},
  journal   = {IEEE J. Sel. Top. Signal Process.},
  volume    = {18},
  number    = {4},
  pages     = {976--987},
  year      = {2024},
  doi       = {10.1109/JSTSP.2024.3396558}
}

@inproceedings{pine_eval_2025,
  author    = {Pine, Aidan and Lothian, Delaney and Bird, Sonya and Caldecott, Marion and MENEŦIYE and PENÁĆ and Richmond, Korin and Swallow, Tye and SX̱EDŦELISIYE and Valentini-Botinhao, Cassia and Wells, Dan and Littell, Patrick},
  title     = {Practical \& Contextual Speech Synthesis Evaluation},
  booktitle = {Proc. SSW},
  year      = {2025}
}

@inproceedings{taylor_festival_1998,
  author    = {Taylor, Paul and Black, Alan W. and Caley, Richard},
  title     = {The Architecture of the {Festival} Speech Synthesis System},
  booktitle = {Proc. SSW},
  year      = {1998},
  publisher = {ISCA}
}

@article{tokuda_hts_2013,
  author    = {Tokuda, Keiichi and Nankaku, Yoshihiko and Toda, Tomoki and Zen, Heiga and Yamagishi, Junichi and Oura, Keiichiro},
  title     = {Speech Synthesis Based on Hidden {Markov} Models},
  journal   = {Proc. IEEE},
  volume    = {101},
  number    = {9},
  pages     = {2060--2086},
  year      = {2013},
  doi       = {10.1109/JPROC.2013.2258885}
}

@inproceedings{kong_diffwave_2021,
  author    = {Kong, Zhifeng and Ping, Wei and Huang, Jiaji and Zhao, Kexin and Catanzaro, Bryan},
  title     = {{DiffWave}: A Versatile Diffusion Model for Audio Synthesis},
  booktitle = {Proc. ICLR},
  year      = {2021},
  url       = {https://openreview.net/forum?id=a-Hm9Ts_C9}
}

@article{lakhotia_gslm_2021,
  author    = {Lakhotia, Kushal and Kharitonov, Eugene and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Abdelrahman and others},
  title     = {On Generative Spoken Language Modeling from Raw Audio},
  journal   = {Trans. Assoc. Comput. Linguist.},
  volume    = {9},
  pages     = {1336--1354},
  year      = {2021},
  doi       = {10.1162/tacl_a_00430}
}

@inproceedings{prenger_waveglow_2019,
  author    = {Prenger, Ryan and Valle, Rafael and Catanzaro, Bryan},
  title     = {{WaveGlow}: A Flow-Based Generative Network for Speech Synthesis},
  booktitle = {Proc. ICASSP},
  pages     = {3617--3621},
  year      = {2019},
  doi       = {10.1109/ICASSP.2019.8683143}
}

@inproceedings{kim_vits_2021,
  author    = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  title     = {Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech},
  booktitle = {Proc. ICML},
  pages     = {5555--5566},
  year      = {2021},
  publisher = {PMLR}
}

@inproceedings{park_speechssm_2025,
  author    = {Park, Se Jin and Salazar, Julian and Jansen, Aren and Kinoshita, Keisuke and Ro, Yong Man and Skerry-Ryan, R. J.},
  title     = {Long-form Speech Generation with Spoken Language Models},
  booktitle = {Proc. ICML},
  year      = {2025}
}

@inproceedings{ling_blizzard_2021,
  author    = {Ling, Zhen-Hua and Zhou, Xiao and King, Simon},
  title     = {The {Blizzard Challenge} 2021},
  booktitle = {Proc. Blizzard Challenge Workshop},
  year      = {2021}
}

@misc{ttsarena,
  author    = {{Hugging Face}},
  title     = {Text to Speech Arena},
  howpublished = {\url{https://huggingface.co/spaces/TTS-AGI/TTS-Arena}},
  year      = {2024}
}

@misc{vctk,
  author    = {Yamagishi, Junichi and Veaux, Christophe and MacDonald, Kirsten},
  title     = {{CSTR VCTK} Corpus: English Multi-speaker Corpus for {CSTR} Voice Cloning Toolkit (version 0.92)},
  publisher = {University of Edinburgh. The Centre for Speech Technology Research (CSTR)},
  year      = {2019},
  doi       = {10.7488/ds/2645}
}

@inproceedings{oord_wavenet_2016,
  author    = {van den Oord, A{\"a}ron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  title     = {{WaveNet}: A Generative Model for Raw Audio},
  booktitle = {Proc. SSW},
  pages     = {125},
  year      = {2016}
}

@article{tan_survey_2021,
  author    = {Tan, Xu and Qin, Tao and Soong, Frank and Liu, Tie-Yan},
  title     = {A Survey on Neural Speech Synthesis},
  journal   = {arXiv preprint arXiv:2106.15561},
  year      = {2021}
}

@inproceedings{wu_merlin_2016,
  author    = {Wu, Zhizheng and Watts, Oliver and King, Simon},
  title     = {Merlin: An Open Source Neural Network Speech Synthesis System},
  booktitle = {Proc. SSW},
  pages     = {202--207},
  year      = {2016}
}

@inproceedings{yao_g2p_2015,
  author    = {Yao, Kaisheng and Zweig, Geoffrey},
  title     = {Sequence-to-Sequence Neural Net Models for Grapheme-to-Phoneme Conversion},
  booktitle = {Proc. Interspeech},
  pages     = {1506--1510},
  year      = {2015},
  doi       = {10.21437/Interspeech.2015-350}
}

@article{chen_f5_2024,
  author    = {Chen, Yushen and Niu, Zhikang and Ma, Ziyang and Deng, Keqi and Wang, Chunhui and Zhao, Jian and Yu, Kai and Chen, Xie},
  title     = {{F5-TTS}: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching},
  journal   = {arXiv preprint arXiv:2410.06885},
  year      = {2024}
}

@inproceedings{wang_slmeval_2024,
  author    = {Wang, Siyang and Sz{\'e}kely, {\'E}va},
  title     = {Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model},
  booktitle = {Proc. LREC-COLING},
  pages     = {16300--16310},
  year      = {2024}
}

@inproceedings{kong_hifigan_2020,
  author    = {Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  title     = {{HiFi-GAN}: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis},
  booktitle = {Proc. NeurIPS},
  volume    = {33},
  pages     = {17022--17033},
  year      = {2020}
}

@inproceedings{kim_glowtts_2020,
  author    = {Kim, Jaehyeon and Kim, Sungwon and Kong, Jungil and Yoon, Sungroh},
  title     = {{Glow-TTS}: A Generative Flow for Text-to-Speech via Monotonic Alignment Search},
  booktitle = {Proc. NeurIPS},
  volume    = {33},
  pages     = {8067--8077},
  year      = {2020}
}

@inproceedings{kalchbrenner_wavernn_2018,
  author    = {Kalchbrenner, Nal and Elsen, Erich and Simonyan, Karen and Noury, Seb and Casagrande, Norman and Lockhart, Edward and Stimberg, Florian and van den Oord, Aaron and Dieleman, Sander and Kavukcuoglu, Koray},
  title     = {Efficient Neural Audio Synthesis},
  booktitle = {Proc. ICML},
  pages     = {2418--2427},
  year      = {2018}
}

@inproceedings{peng_paranet_2020,
  author    = {Peng, Kainan and Ping, Wei and Song, Zhao and Zhao, Kexin},
  title     = {Non-Autoregressive Neural Text-to-Speech},
  booktitle = {Proc. ICML},
  pages     = {7586--7595},
  year      = {2020}
}

@inproceedings{arik_deepvoice_2017,
  author    = {Ar{\i}k, Sercan {\"O}. and Chrzanowski, Mike and Coates, Adam and Diamos, Gregory and Gibiansky, Andrew and Kang, Yongguo and Li, Xian and Miller, John and Ng, Andrew and Raiman, Jonathan and others},
  title     = {Deep Voice: Real-time Neural Text-to-Speech},
  booktitle = {Proc. ICML},
  pages     = {196--204},
  year      = {2017}
}

@inproceedings{gibiansky_deepvoice2_2017,
  author    = {Gibiansky, Andrew and Arik, Sercan and Diamos, Gregory and Miller, John and Peng, Kainan and Ping, Wei and Raiman, Jonathan and Zhou, Yanqi},
  title     = {Deep Voice 2: Multi-speaker Neural Text-to-Speech},
  booktitle = {Proc. NeurIPS},
  volume    = {30},
  year      = {2017}
}

@inproceedings{ling_hybrid_2007,
  author    = {Ling, Zhen-Hua and Wang, Ren-Hua},
  title     = {{HMM}-based Hierarchical Unit Selection Combining {Kullback-Leibler} Divergence with Likelihood Criterion},
  booktitle = {Proc. ICASSP},
  pages     = {1229--1232},
  year      = {2007},
  doi       = {10.1109/ICASSP.2007.367298}
}

@article{tukoda_hmm_2013,
  author    = {Tokuda, Keiichi and Nankaku, Yoshihiko and Toda, Tomoki and Zen, Heiga and Yamagishi, Junichi and Oura, Keiichiro},
  title     = {Speech Synthesis Based on Hidden {Markov} Models},
  journal   = {Proc. IEEE},
  volume    = {101},
  number    = {9},
  pages     = {2060--2086},
  year      = {2013},
  doi       = {10.1109/JPROC.2013.2258885}
}

@inproceedings{hunt_unit_1996,
  author    = {Hunt, Andrew J. and Black, Alan W.},
  title     = {Unit Selection in a Concatenative Speech Synthesis System Using a Large Speech Database},
  booktitle = {Proc. ICASSP},
  pages     = {373--376},
  year      = {1996},
  doi       = {10.1109/ICASSP.1996.540368}
}

@inproceedings{le_voicebox_2023,
  author    = {Le, Matthew and Vyas, Apoorv and Shi, Bowen and Karrer, Brian and Sari, Leda and Moritz, Rashel and Williamson, Mary and Manohar, Vimal and Adi, Yossi and Mahadeokar, Jay and Hsu, Wei-Ning},
  title     = {Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale},
  booktitle = {Proc. NeurIPS},
  volume    = {36},
  pages     = {52046--52088},
  year      = {2023}
}

@article{wang_valle_2023,
  author    = {Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  title     = {Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers},
  journal   = {arXiv preprint arXiv:2301.02111},
  year      = {2023}
}

@article{badlani_multilingual_2023,
  author    = {Badlani, Rohan and Valle, Rafael and Shih, Kevin J. and Santos, João Felipe and Gururani, Siddharth and Catanzaro, Bryan},
  title     = {Multilingual Multiaccented Multispeaker {TTS} with {RADTTS}},
  journal   = {arXiv preprint arXiv:2301.10335},
  year      = {2023}
}

@article{borsos_soundstorm_2023,
  author    = {Borsos, Zal{\'a}n and Sharifi, Matt and Vincent, Damien and Kharitonov, Eugene and Zeghidour, Neil and Tagliasacchi, Marco},
  title     = {Soundstorm: Efficient Parallel Audio Generation},
  journal   = {arXiv preprint arXiv:2305.09636},
  year      = {2023}
}

@inproceedings{du_multi-speaker_2023,
  author    = {Du, Chenpeng and Guo, Yiwei and Shen, Feiyu and Yu, Kai},
  title     = {Multi-Speaker Multi-Lingual {VQTTS} System for {LIMMITS} 2023 Challenge},
  booktitle = {Proc. ICASSP},
  year      = {2023},
  doi       = {10.1109/ICASSP49357.2023.10094943}
}

@article{zhang_speak_2023,
  author    = {Zhang, Ziqiang and Zhou, Long and Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  title     = {Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling},
  journal   = {arXiv preprint arXiv:2303.03926},
  year      = {2023}
}

@inproceedings{ren_revisiting_2022,
  author    = {Ren, Yi and Tan, Xu and Qin, Tao and Zhao, Zhou and Liu, Tie-Yan},
  title     = {Revisiting Over-Smoothness in Text to Speech},
  booktitle = {Proc. ACL},
  pages     = {2739--2751},
  year      = {2022},
  doi       = {10.18653/v1/2022.acl-main.202}
}

@inproceedings{ren_fastspeech_2021,
  author    = {Ren, Yi and Hu, Chenxu and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  title     = {{FastSpeech} 2: Fast and High-Quality End-to-End Text to Speech},
  booktitle = {Proc. ICLR},
  year      = {2021},
  url       = {https://openreview.net/forum?id=piLP_v-BGrj}
}

@inproceedings{huang_fastdiff_2022,
  author    = {Huang, Rongjie and Lam, Max W. Y. and Wang, Jun and Su, Dan and Yu, Dong and Ren, Yi and Zhao, Zhou},
  title     = {{FastDiff}: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis},
  booktitle = {Proc. IJCAI},
  pages     = {4149--4155},
  year      = {2022},
  doi       = {10.24963/ijcai.2022/576}
}

@inproceedings{kroger_articulatory_2023,
  author    = {Kröger, Bernd J.},
  title     = {Articulatory Speech Synthesis in the Context of Speech Research and Speech Technology: Review and Prospect},
  booktitle = {Proc. ESSV},
  year      = {2023}
}

@inproceedings{shen_natural_2018,
  author    = {Shen, Jonathan and Pang, Ruoming and Weiss, Ron J. and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, R. J. and others},
  title     = {Natural {TTS} Synthesis by Conditioning {WaveNet} on Mel Spectrogram Predictions},
  booktitle = {Proc. ICASSP},
  pages     = {4779--4783},
  year      = {2018},
  doi       = {10.1109/ICASSP.2018.8461368}
}

@article{casanova_xtts_2024,
  author    = {Casanova, Edresson and Davis, Kelly and Gölge, Eren and Göknar, Görkem and Gulea, Iulian and Hart, Logan and Aljafari, Aya and Meyer, Joshua and Morais, Reuben and Olayemi, Samuel and others},
  title     = {{XTTS}: A Massively Multilingual Zero-Shot Text-to-Speech Model},
  journal   = {arXiv preprint arXiv:2401.02839},
  year      = {2024}
}

@article{liu_maximizing_2019,
  author    = {Liu, Peng and Wu, Xixin and Kang, Shiyin and Li, Guangzhi and Su, Dan and Yu, Dong},
  title     = {Maximizing Mutual Information for {Tacotron}},
  journal   = {arXiv preprint arXiv:1909.01145},
  year      = {2019}
}

@article{tan_naturalspeech_2024,
  author    = {Tan, Xu and Chen, Jiawei and Liu, Haohe and Cong, Jian and Zhang, Chen and Liu, Yanqing and Wang, Xi and Leng, Yichong and Yi, Yuanhao and He, Lei and others},
  title     = {{NaturalSpeech}: End-to-End Text-to-Speech Synthesis with Human-Level Quality},
  journal   = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume    = {46},
  number    = {10},
  pages     = {6803--6816},
  year      = {2024},
  doi       = {10.1109/TPAMI.2024.3387865}
}

@inproceedings{popov_gradtts_2021,
  author    = {Popov, Vadim and Vovk, Ivan and Gogoryan, Vladimir and Sadekova, Tasnima and Kudinov, Mikhail},
  title     = {Grad-{TTS}: A Diffusion Probabilistic Model for Text-to-Speech},
  booktitle = {Proc. ICML},
  pages     = {8599--8608},
  year      = {2021}
}

@article{budzianowski_pheme_2024,
  author    = {Budzianowski, Paweł and Sereda, Taras and Cichy, Tomasz and Vulić, Ivan},
  title     = {Pheme: Efficient and Conversational Speech Generation},
  journal   = {arXiv preprint arXiv:2401.02839},
  year      = {2024}
}

@inproceedings{li_styletts_2023,
  author    = {Li, Yinghao Aaron and Han, Cong and Raghavan, Vinay and Mischler, Gavin and Mesgarani, Nima},
  title     = {{StyleTTS} 2: Towards Human-Level Text-to-Speech Through Style Diffusion and Adversarial Training with Large Speech Language Models},
  booktitle = {Proc. NeurIPS},
  volume    = {36},
  pages     = {56782--56822},
  year      = {2023}
}

@inproceedings{lancucki_fastpitch_2021,
  author    = {Łańcucki, Adrian},
  title     = {{FastPitch}: Parallel Text-to-Speech with Pitch Prediction},
  booktitle = {Proc. ICASSP},
  pages     = {6588--6592},
  year      = {2021},
  doi       = {10.1109/ICASSP39728.2021.9413889}
}

@inproceedings{wang_tacotron_2017,
  author    = {Wang, Yuxuan and Skerry-Ryan, R. J. and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J. and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and others},
  title     = {Tacotron: Towards End-to-End Speech Synthesis},
  booktitle = {Proc. Interspeech},
  pages     = {4006--4010},
  year      = {2017},
  doi       = {10.21437/Interspeech.2017-1452}
}

@article{andreev_hifi_2022,
  author    = {Andreev, Pavel and Alanov, Aibek and Ivanov, Oleg and Vetrov, Dmitry},
  title     = {{HiFi}++: A Unified Framework for Neural Vocoding, Bandwidth Extension and Speech Enhancement},
  journal   = {arXiv preprint arXiv:2203.13086},
  year      = {2022}
}

@article{ju_naturalspeech_2024,
  author    = {Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and others},
  title     = {{NaturalSpeech} 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models},
  journal   = {arXiv preprint arXiv:2403.03100},
  year      = {2024}
}

@inproceedings{casanova_yourtts_2022,
  author    = {Casanova, Edresson and Weber, Julian and Shulby, Christopher D. and Junior, Arnaldo Candido and Gölge, Eren and Ponti, Moacir A.},
  title     = {{YourTTS}: Towards Zero-Shot Multi-Speaker {TTS} and Zero-Shot Voice Conversion for Everyone},
  booktitle = {Proc. ICML},
  pages     = {2743--2762},
  year      = {2022}
}

@inproceedings{binkowski_high_2019,
  author    = {Bińkowski, Mikołaj and Donahue, Jeff and Dieleman, Sander and Clark, Aidan and Elsen, Erich and Casagrande, Norman and Cobo, Luis C. and Simonyan, Karen},
  title     = {High Fidelity Speech Synthesis with Adversarial Networks},
  booktitle = {Proc. ICLR},
  year      = {2019},
  url       = {https://openreview.net/forum?id=r1gf4lntDr}
}

@inproceedings{kim_conditional_2021,
  author    = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  title     = {Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech},
  booktitle = {Proc. ICML},
  pages     = {5555--5566},
  year      = {2021}
}

@inproceedings{luo_lightspeech_2021,
  author    = {Luo, Renqian and Tan, Xu and Wang, Rui and Qin, Tao and Li, Jinzhu and Zhao, Sheng and Chen, Enhong and Liu, Tie-Yan},
  title     = {{LightSpeech}: Lightweight and Fast Text to Speech with Neural Architecture Search},
  booktitle = {Proc. ICASSP},
  pages     = {6593--6597},
  year      = {2021},
  doi       = {10.1109/ICASSP39728.2021.9413554}
}

@article{chen_vall-e_2024,
  author    = {Chen, Sanyuan and Liu, Shujie and Zhou, Long and Liu, Yanqing and Tan, Xu and Li, Jinyu and Zhao, Sheng and Qian, Yao and Wei, Furu},
  title     = {{VALL-E} 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers},
  journal   = {arXiv preprint arXiv:2406.05370},
  year      = {2024}
}

@inproceedings{pine_requirements_2022,
  author    = {Pine, Aidan and Wells, Dan and Brinklow, Nathan and Littell, Patrick and Richmond, Korin},
  title     = {Requirements and Motivations of Low-Resource Speech Synthesis for Language Revitalization},
  booktitle = {Proc. ACL},
  pages     = {198--206},
  year      = {2022},
  doi       = {10.18653/v1/2022.acl-main.15}
}

@inproceedings{hayashi_espnet-tts_2020,
  author    = {Hayashi, Tomoki and Yamamoto, Ryuichi and Inoue, Katsuki and Yoshimura, Takenori and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya and Zhang, Yu and Tan, Xu},
  title     = {{ESPnet-TTS}: Unified, Reproducible, and Integratable Open Source End-to-End Text-to-Speech Toolkit},
  booktitle = {Proc. ICASSP},
  pages     = {7544--7548},
  year      = {2020},
  doi       = {10.1109/ICASSP40207.2020.9053530}
}

@inproceedings{ren_fastspeech_2019,
  author    = {Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  title     = {{FastSpeech}: Fast, Robust and Controllable Text to Speech},
  booktitle = {Proc. NeurIPS},
  volume    = {32},
  year      = {2019}
}

@article{lyth_parler_2024,
  author    = {Lyth, Dan and King, Simon},
  title     = {Natural Language Guidance of High-Fidelity Text-to-Speech with Synthetic Annotations},
  journal   = {arXiv preprint arXiv:2402.01912},
  year      = {2024}
}

@inproceedings{eskimez_e2_2024,
  author    = {Eskimez, Sefik Emre and Wang, Xiaofei and Thakker, Manthan and Li, Canrun and Tsai, Chung-Hsien and Xiao, Zhen and Yang, Hemin and Zhu, Zirun and Tang, Min and Tan, Xu and others},
  title     = {{E2 TTS}: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot {TTS}},
  booktitle = {Proc. IEEE SLT},
  year      = {2024}
}

@inproceedings{mehta_neuralhmm_2022,
  author    = {Mehta, Shivam and Sz{\'e}kely, {\'E}va and Beskow, Jonas and Henter, Gustav Eje},
  title     = {Neural {HMM}s Are All You Need (for High-Quality Attention-Free {TTS})},
  booktitle = {Proc. ICASSP},
  pages     = {6222--6226},
  year      = {2022},
  doi       = {10.1109/ICASSP43903.2022.9746390}
}

@misc{bark_2023,
  author    = {Suno},
  title     = {Bark},
  year      = {2023},
  howpublished = {\url{https://github.com/suno-ai/bark}},
  note      = {GitHub repository}
}

@misc{BarkVC_2023,
  author    = {Mylo},
  title     = {Bark Voice Cloning {HuBERT} Quantizer},
  year      = {2023},
  howpublished = {\url{https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer}},
  note      = {GitHub repository}
}

@article{liao_fishspeech_2024,
  author    = {Liao, Shijia and Wang, Yuxuan and Li, Tianyu and Cheng, Yifan and Zhang, Ruoyi and Zhou, Rongzhi and Xing, Yijin},
  title     = {{Fish-Speech}: Leveraging Large Language Models for Advanced Multilingual Text-to-Speech Synthesis},
  journal   = {arXiv preprint arXiv:2411.01156},
  year      = {2024}
}

@misc{RVCBoss_gptsovits_2024,
  author    = {{RVC-Boss}},
  title     = {{GPT-SoVITS}},
  year      = {2024},
  howpublished = {\url{https://github.com/RVC-Boss/GPT-SoVITS}},
  note      = {GitHub repository}
}

@inproceedings{Fan2015,
  author    = {Fan, Yuchen and Qian, Yao and Soong, Frank K. and He, Lei},
  title     = {Multi-speaker Modeling and Speaker Adaptation for {DNN}-Based {TTS} Synthesis},
  booktitle = {Proc. ICASSP},
  pages     = {4415--4419},
  year      = {2015},
  doi       = {10.1109/ICASSP.2015.7178805}
}

@inproceedings{Gritsenko2020,
  author    = {Gritsenko, Alexey and Salimans, Tim and van den Berg, Rianne and Snoek, Jasper and Kalchbrenner, Nal},
  title     = {A Spectral Energy Distance for Parallel Speech Synthesis},
  booktitle = {Proc. NeurIPS},
  volume    = {33},
  pages     = {13062--13072},
  year      = {2020}
}

@inproceedings{Wagner2019,
  author    = {Wagner, Petra and Beskow, Jonas and Betz, Simon and Edlund, Jens and Gustafson, Joakim and Eje, Gustav and Henter, S{\'e}bastien Le Maguer and Malisz, Zofia and Sz{\'e}kely, {\'E}va and T{\aa}nnander, Christina and others},
  title     = {Speech Synthesis Evaluation --- State-of-the-Art Assessment and Suggestion for a Novel Research Program},
  booktitle = {Proc. SSW},
  pages     = {11--16},
  year      = {2019},
  doi       = {10.21437/SSW.2019-2}
}

@inbook{Campbell2007,
  author    = {Campbell, Nick},
  title     = {Evaluation of Speech Synthesis},
  booktitle = {Evaluation of Text and Speech Systems},
  pages     = {29--64},
  year      = {2007},
  publisher = {Springer},
  doi       = {10.1007/978-3-540-70617-5_2}
}

@misc{shoukanlabs_vokan_2024,
  author    = {Shoukanlabs},
  title     = {Vokan},
  year      = {2024},
  howpublished = {\url{https://huggingface.co/ShoukanLabs/Vokan}},
  note      = {Hugging Face repository}
}

@article{lee_hierspeechpp_2023,
  author    = {Lee, Sang-Hoon and Choi, Ha-Yeong and Kim, Seung-Bin and Lee, Seong-Whan},
  title     = {{HierSpeech++}: Bridging the Gap Between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-Shot Speech Synthesis},
  journal   = {arXiv preprint arXiv:2311.12454},
  year      = {2023}
}

@article{wang_maskgct_2024,
  author    = {Wang, Yuancheng and Zhan, Haoyue and Liu, Liwei and Zeng, Ruihong and Guo, Haotian and Zheng, Jiachen and Zhang, Qiang and Zhang, Xueyao and Zhang, Shunsi and Wu, Zhizheng},
  title     = {{MaskGCT}: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer},
  journal   = {arXiv preprint arXiv:2409.00750},
  year      = {2024}
}

@inproceedings{zhang_amphion_2024,
  author    = {Zhang, Xueyao and Xue, Liumeng and Gu, Yicheng and Wang, Yuancheng and Li, Jiaqi and He, Haorui and Wang, Chaoren and Song, Ting and Chen, Xi and Fang, Zihao and Chen, Haopeng and Zhang, Junan and Tang, Tze Ying and Zou, Lexiao and Wang, Mingxuan and Han, Jun and Chen, Kai and Li, Haizhou and Wu, Zhizheng},
  title     = {Amphion: An Open-Source Audio, Music and Speech Generation Toolkit},
  booktitle = {Proc. IEEE SLT},
  year      = {2024}
}

@misc{sharma_metavoice_2024,
  author    = {Sharma, Siddharth and Perić, Luca and Aggarwal, Vatsal and others},
  title     = {{MetaVoice}},
  year      = {2024},
  howpublished = {\url{https://github.com/metavoiceio/metavoice-src}},
  note      = {GitHub repository}
}

@misc{lacombe_parlertts_2024,
  author    = {Lacombe, Yoach and Srivastav, Vaibhav and Gandhi, Sanchit},
  title     = {{Parler-TTS}},
  year      = {2024},
  howpublished = {\url{https://github.com/huggingface/parler-tts}},
  note      = {GitHub repository}
}

@article{qin_openvoice_2023,
  author    = {Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
  title     = {{OpenVoice}: Versatile Instant Voice Cloning},
  journal   = {arXiv preprint arXiv:2312.01479},
  year      = {2023}
}

@inproceedings{ao_speecht5_2022,
  author    = {Ao, Junyi and Wang, Rui and Zhou, Long and Wang, Chengyi and Ren, Shuo and Wu, Yu and Liu, Shujie and Ko, Tom and Li, Qing and Zhang, Yu and others},
  title     = {{SpeechT5}: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing},
  booktitle = {Proc. ACL},
  pages     = {5723--5733},
  year      = {2022},
  doi       = {10.18653/v1/2022.acl-main.414}
}

@article{betker_tortoise_2023,
  author    = {Betker, James},
  title     = {Better Speech Synthesis Through Scaling},
  journal   = {arXiv preprint arXiv:2305.07243},
  year      = {2023}
}

@inproceedings{zhang_vevo_2025,
  author       = {Zhang, Xueyao and Zhang, Xiaohui and Peng, Kainan and Tang, Zhenyu and Manohar, Vimal and Liu, Yingru and Hwang, Jeff and Li, Dangna and Wang, Yuhao and Chan, Julian and Huang, Yuan and Wu, Zhizheng and Ma, Mingbo},
  title        = {Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement},
  booktitle    = {Proc. ICLR},
  year         = {2025}
}

@inproceedings{peng_voicecraft_2024,
  author    = {Peng, Puyuan and Huang, Po-Yao and Li, Shang-Wen and Mohamed, Abdelrahman and Harwath, David},
  title     = {{VoiceCraft}: Zero-Shot Speech Editing and Text-to-Speech in the Wild},
  booktitle = {Proc. ACL},
  pages     = {10188--10206},
  year      = {2024}
}

@misc{clapa_WhisperSpeech_2024,
  author    = {Cłapa, Jakub Piotr and others},
  title     = {{WhisperSpeech}},
  year      = {2024},
  howpublished = {\url{https://github.com/WhisperSpeech/WhisperSpeech}},
  note      = {GitHub repository}
}